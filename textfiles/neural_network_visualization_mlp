digraph {
	graph [size="18.45,18.45"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2023831101872 [label="
 (1, 8)" fillcolor=darkolivegreen1]
	2017543587104 [label=AddmmBackward0]
	2017543591424 -> 2017543587104
	2019973749872 [label="layers.17.bias
 (8)" fillcolor=lightblue]
	2019973749872 -> 2017543591424
	2017543591424 [label=AccumulateGrad]
	2017543591232 -> 2017543587104
	2017543591232 [label=LeakyReluBackward0]
	2017543592192 -> 2017543591232
	2017543592192 [label=NativeBatchNormBackward0]
	2017543597136 -> 2017543592192
	2017543597136 [label=AddmmBackward0]
	2017543591712 -> 2017543597136
	2019973756400 [label="layers.14.bias
 (128)" fillcolor=lightblue]
	2019973756400 -> 2017543591712
	2017543591712 [label=AccumulateGrad]
	2017543602032 -> 2017543597136
	2017543602032 [label=LeakyReluBackward0]
	2017543600544 -> 2017543602032
	2017543600544 [label=NativeBatchNormBackward0]
	2017543589456 -> 2017543600544
	2017543589456 [label=AddmmBackward0]
	2017543590560 -> 2017543589456
	2019973758512 [label="layers.11.bias
 (256)" fillcolor=lightblue]
	2019973758512 -> 2017543590560
	2017543590560 [label=AccumulateGrad]
	2017543600880 -> 2017543589456
	2017543600880 [label=LeakyReluBackward0]
	2017543596848 -> 2017543600880
	2017543596848 [label=NativeBatchNormBackward0]
	2017543599920 -> 2017543596848
	2017543599920 [label=AddmmBackward0]
	2017543595936 -> 2017543599920
	2019973752656 [label="layers.7.bias
 (512)" fillcolor=lightblue]
	2019973752656 -> 2017543595936
	2017543595936 [label=AccumulateGrad]
	2017543595744 -> 2017543599920
	2017543595744 [label=LeakyReluBackward0]
	2020125866160 -> 2017543595744
	2020125866160 [label=AddmmBackward0]
	2020125864528 -> 2020125866160
	2020125603600 [label="layers.4.bias
 (1024)" fillcolor=lightblue]
	2020125603600 -> 2020125864528
	2020125864528 [label=AccumulateGrad]
	2020125855984 -> 2020125866160
	2020125855984 [label=LeakyReluBackward0]
	2017771643296 -> 2020125855984
	2017771643296 [label=AddmmBackward0]
	2020126613824 -> 2017771643296
	2020125594096 [label="layers.1.bias
 (2048)" fillcolor=lightblue]
	2020125594096 -> 2020126613824
	2020126613824 [label=AccumulateGrad]
	2019967230320 -> 2017771643296
	2019967230320 [label=NativeBatchNormBackward0]
	2023836391344 -> 2019967230320
	2020125595824 [label="layers.0.weight
 (1185)" fillcolor=lightblue]
	2020125595824 -> 2023836391344
	2023836391344 [label=AccumulateGrad]
	2023836391584 -> 2019967230320
	2020125592176 [label="layers.0.bias
 (1185)" fillcolor=lightblue]
	2020125592176 -> 2023836391584
	2023836391584 [label=AccumulateGrad]
	2023836398688 -> 2017771643296
	2023836398688 [label=TBackward0]
	2023836397248 -> 2023836398688
	2020125603696 [label="layers.1.weight
 (2048, 1185)" fillcolor=lightblue]
	2020125603696 -> 2023836397248
	2023836397248 [label=AccumulateGrad]
	2020125865440 -> 2020125866160
	2020125865440 [label=TBackward0]
	2019967224272 -> 2020125865440
	2020125589872 [label="layers.4.weight
 (1024, 2048)" fillcolor=lightblue]
	2020125589872 -> 2019967224272
	2019967224272 [label=AccumulateGrad]
	2017543595600 -> 2017543599920
	2017543595600 [label=TBackward0]
	2019967154256 -> 2017543595600
	2020125591312 [label="layers.7.weight
 (512, 1024)" fillcolor=lightblue]
	2020125591312 -> 2019967154256
	2019967154256 [label=AccumulateGrad]
	2017543600976 -> 2017543596848
	2019973753424 [label="layers.8.weight
 (512)" fillcolor=lightblue]
	2019973753424 -> 2017543600976
	2017543600976 [label=AccumulateGrad]
	2017543589312 -> 2017543596848
	2019973756496 [label="layers.8.bias
 (512)" fillcolor=lightblue]
	2019973756496 -> 2017543589312
	2017543589312 [label=AccumulateGrad]
	2017543597616 -> 2017543589456
	2017543597616 [label=TBackward0]
	2017543593824 -> 2017543597616
	2019973745360 [label="layers.11.weight
 (256, 512)" fillcolor=lightblue]
	2019973745360 -> 2017543593824
	2017543593824 [label=AccumulateGrad]
	2017543589216 -> 2017543600544
	2019973744208 [label="layers.12.weight
 (256)" fillcolor=lightblue]
	2019973744208 -> 2017543589216
	2017543589216 [label=AccumulateGrad]
	2017543600832 -> 2017543600544
	2019973744400 [label="layers.12.bias
 (256)" fillcolor=lightblue]
	2019973744400 -> 2017543600832
	2017543600832 [label=AccumulateGrad]
	2017543600016 -> 2017543597136
	2017543600016 [label=TBackward0]
	2017543599056 -> 2017543600016
	2019973753616 [label="layers.14.weight
 (128, 256)" fillcolor=lightblue]
	2019973753616 -> 2017543599056
	2017543599056 [label=AccumulateGrad]
	2017543588352 -> 2017543592192
	2019973744592 [label="layers.15.weight
 (128)" fillcolor=lightblue]
	2019973744592 -> 2017543588352
	2017543588352 [label=AccumulateGrad]
	2017543591472 -> 2017543592192
	2019973756880 [label="layers.15.bias
 (128)" fillcolor=lightblue]
	2019973756880 -> 2017543591472
	2017543591472 [label=AccumulateGrad]
	2017543586576 -> 2017543587104
	2017543586576 [label=TBackward0]
	2017543599008 -> 2017543586576
	2019973751696 [label="layers.17.weight
 (8, 128)" fillcolor=lightblue]
	2019973751696 -> 2017543599008
	2017543599008 [label=AccumulateGrad]
	2017543587104 -> 2023831101872
}
