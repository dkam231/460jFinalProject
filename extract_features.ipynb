{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!pip install git+https://git.ffmpeg.org/ffmpeg.git\n",
    "!pip install ffprobe-python\n",
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='C:/Users/divya/OneDrive/Documents/UTAUSTIN/Semester6/460j/final_project_data/fma_small'\n",
    "file_path='C:/Users/divya/OneDrive/Documents/UTAUSTIN/Semester6/460j/final_project_data/fma_small/000/000002.mp3'\n",
    "output_path = 'C:/Users/divya/OneDrive/Documents/UTAUSTIN/Semester6/460j/460jFinalProject/extracted_features_combined_mpwavvac.csv'\n",
    "\n",
    "# Paths to the datasets\n",
    "# tracks_path = '/Users/dkamboj6/Recitation/460j_fma_dataset/fma_metadata/tracks.csv'\n",
    "# genres_path = '/Users/dkamboj6/Recitation/460j_fma_dataset/fma_metadata/genres.csv'\n",
    "tracks_path=f\"C:/Users/divya/OneDrive/Documents/UTAUSTIN/Semester6/460j/final_project_data/fma_metadata/tracks.csv\"\n",
    "genres_path= f\"C:/Users/divya/OneDrive/Documents/UTAUSTIN/Semester6/460j/final_project_data/fma_metadata/genres.csv\"\n",
    "# Load data\n",
    "tracks = pd.read_csv(tracks_path, index_col=0, header=[0, 1])\n",
    "genres = pd.read_csv(genres_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:/Users/divya/OneDrive/Documents/UTAUSTIN/Semester6/460j/final_project_data/fma_small/000/000002.mp3\"\n",
    "print(\"Checking file path:\", file_path)\n",
    "print(\"File exists:\", os.path.exists(file_path))\n",
    "\n",
    "# List files in the directory to verify path and file names\n",
    "print(\"Files in directory:\")\n",
    "for file in os.listdir(os.path.dirname(file_path)):\n",
    "    print(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from pydub import AudioSegment\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2Model\n",
    "def extract_all_features(file_path):\n",
    "    try:\n",
    "        # Check if the file exists\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"No file found at {file_path}\")\n",
    "\n",
    "        audio_segment = AudioSegment.from_mp3(file_path)\n",
    "        samples = audio_segment.set_frame_rate(16000).set_channels(1).get_array_of_samples()\n",
    "        wav_samples = np.array(samples).astype(np.float32)\n",
    "\n",
    "        processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "        model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "        inputs = processor(wav_samples, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs.input_values)\n",
    "        features = outputs.last_hidden_state.squeeze().numpy()\n",
    "\n",
    "        track_id = int(os.path.splitext(os.path.basename(file_path))[0])\n",
    "        return features, track_id\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None, None\n",
    "extract_all_features_file=extract_all_features(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(file_path):\n",
    "    try:\n",
    "        # Load audio file\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "        \n",
    "        # Get the Mel-frequency cepstral coefficients\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        mfccs_processed = np.mean(mfcc.T,axis=0)\n",
    "        \n",
    "        # Get the spectral contrast\n",
    "        stft = np.abs(librosa.stft(y))\n",
    "        contrast = librosa.feature.spectral_contrast(S=stft, sr=sr)\n",
    "        contrast_processed = np.mean(contrast.T,axis=0)\n",
    "        \n",
    "        # Get the chroma feature\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        chroma_processed = np.mean(chroma.T,axis=0)\n",
    "        \n",
    "        # Get the mel-scaled spectrogram\n",
    "        mel = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "        mel_processed = np.mean(mel.T,axis=0)\n",
    "\n",
    "        # Concatenate all features into one array\n",
    "        features = np.hstack([mfccs_processed, contrast_processed, chroma_processed, mel_processed])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered while parsing file: {file_path}, error: {e}\")\n",
    "        return None \n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_genre_metadata(tracks_path):\n",
    "    # Load track metadata for genre labels\n",
    "    tracks_df = pd.read_csv(tracks_path, index_col=0, header=[0, 1])\n",
    "    genre_labels = tracks_df['track']['genre_top']  # Adjust if the column names are different\n",
    "    return genre_labels.to_dict()\n",
    "\n",
    "# Define the path to your tracks.csv metadata file\n",
    "genre_dict = load_genre_metadata(tracks_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_audio_files(base_directory):\n",
    "    features_list = []\n",
    "    track_ids = []\n",
    "\n",
    "    # Walk through all files in the directory structure\n",
    "    for subdir, dirs, files in os.walk(base_directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.mp3'):\n",
    "\n",
    "                file_path = os.path.join(subdir, file).replace('\\\\','/')\n",
    "\n",
    "                features = extract_all_features(file_path)\n",
    "                if features is not None:\n",
    "                    features_list.append(features)\n",
    "                    # Extract track ID from filename\n",
    "                    track_id = int(file.split('.')[0])\n",
    "                    track_ids.append(track_id)\n",
    "\n",
    "    return features_list, track_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all audio files and collect features\n",
    "features, track_ids = process_all_audio_files(data_dir)\n",
    "\n",
    "# Optionally, load the metadata and merge it with the extracted features\n",
    "tracks_path = '/Users/dkamboj6/Recitation/460j_fma_dataset/fma_metadata/tracks.csv'\n",
    "tracks = pd.read_csv(tracks_path, index_col=0, header=[0, 1])\n",
    "track_genres = tracks['track', 'genre_top']\n",
    "\n",
    "# Create DataFrame\n",
    "features_df = pd.DataFrame(features, index=track_ids)\n",
    "features_df['genre'] = features_df.index.map(track_genres.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "features_df.to_csv(output_path)\n",
    "\n",
    "print(f\"All features with genre saved to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
