{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir=\"C:/Users/divya/OneDrive/Documents/UTAUSTIN/Semester 6/460j/final_project_data/fma_small\"\n",
    "# file_path=\"C:/Users/divya/OneDrive/Documents/UTAUSTIN/Semester 6/460j/final_project_data/fma_small/000/000002.mp3\"\n",
    "train_path = 'C:/Users/divya/OneDrive/Documents/UTAUSTIN/Semester6/460j/460jFinalProject/extracted_features_combined.csv'\n",
    "# train_path = 'C:/Users/divya/OneDrive/Documents/UTAUSTIN/Semester6/460j/460jFinalProject/extracted_features_wav2vec.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=pd.read_csv(train_path, index_col=0)\n",
    "# data_df=pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1176</th>\n",
       "      <th>1177</th>\n",
       "      <th>1178</th>\n",
       "      <th>1179</th>\n",
       "      <th>1180</th>\n",
       "      <th>1181</th>\n",
       "      <th>1182</th>\n",
       "      <th>1183</th>\n",
       "      <th>1184</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.713936</td>\n",
       "      <td>117.760094</td>\n",
       "      <td>-42.334183</td>\n",
       "      <td>38.061005</td>\n",
       "      <td>-23.012323</td>\n",
       "      <td>23.920383</td>\n",
       "      <td>-11.944865</td>\n",
       "      <td>13.687291</td>\n",
       "      <td>-7.294582</td>\n",
       "      <td>4.041143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-162.232422</td>\n",
       "      <td>131.435989</td>\n",
       "      <td>-18.426781</td>\n",
       "      <td>51.631371</td>\n",
       "      <td>-15.444844</td>\n",
       "      <td>23.860094</td>\n",
       "      <td>-7.867664</td>\n",
       "      <td>10.686234</td>\n",
       "      <td>-0.314591</td>\n",
       "      <td>12.864646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-75.631538</td>\n",
       "      <td>154.537613</td>\n",
       "      <td>-63.849487</td>\n",
       "      <td>22.506426</td>\n",
       "      <td>2.425359</td>\n",
       "      <td>10.459981</td>\n",
       "      <td>-13.007332</td>\n",
       "      <td>9.818939</td>\n",
       "      <td>-7.640783</td>\n",
       "      <td>3.136315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>-322.997864</td>\n",
       "      <td>133.684906</td>\n",
       "      <td>15.497437</td>\n",
       "      <td>54.755615</td>\n",
       "      <td>8.718211</td>\n",
       "      <td>37.022747</td>\n",
       "      <td>-2.116411</td>\n",
       "      <td>15.265619</td>\n",
       "      <td>6.175477</td>\n",
       "      <td>-2.599205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>Folk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>-253.314560</td>\n",
       "      <td>157.769379</td>\n",
       "      <td>-6.081675</td>\n",
       "      <td>26.920168</td>\n",
       "      <td>6.813843</td>\n",
       "      <td>15.842272</td>\n",
       "      <td>-12.930041</td>\n",
       "      <td>10.373278</td>\n",
       "      <td>-0.609945</td>\n",
       "      <td>-8.300909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>Folk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0           1          2          3          4          5  \\\n",
       "track_id                                                                       \n",
       "2        -122.713936  117.760094 -42.334183  38.061005 -23.012323  23.920383   \n",
       "5        -162.232422  131.435989 -18.426781  51.631371 -15.444844  23.860094   \n",
       "10        -75.631538  154.537613 -63.849487  22.506426   2.425359  10.459981   \n",
       "140      -322.997864  133.684906  15.497437  54.755615   8.718211  37.022747   \n",
       "141      -253.314560  157.769379  -6.081675  26.920168   6.813843  15.842272   \n",
       "\n",
       "                  6          7         8          9  ...      1176      1177  \\\n",
       "track_id                                             ...                       \n",
       "2        -11.944865  13.687291 -7.294582   4.041143  ...  0.000032  0.000033   \n",
       "5         -7.867664  10.686234 -0.314591  12.864646  ...  0.000039  0.000041   \n",
       "10       -13.007332   9.818939 -7.640783   3.136315  ...  0.000056  0.000066   \n",
       "140       -2.116411  15.265619  6.175477  -2.599205  ...  0.000041  0.000035   \n",
       "141      -12.930041  10.373278 -0.609945  -8.300909  ...  0.000029  0.000025   \n",
       "\n",
       "              1178      1179      1180      1181      1182      1183  \\\n",
       "track_id                                                               \n",
       "2         0.000039  0.000048  0.000078  0.000110  0.000089  0.000050   \n",
       "5         0.000060  0.000092  0.000102  0.000146  0.000153  0.000072   \n",
       "10        0.000069  0.000083  0.000095  0.000103  0.000103  0.000072   \n",
       "140       0.000031  0.000038  0.000050  0.000052  0.000034  0.000024   \n",
       "141       0.000026  0.000048  0.000095  0.000081  0.000036  0.000029   \n",
       "\n",
       "              1184    genre  \n",
       "track_id                     \n",
       "2         0.000029  Hip-Hop  \n",
       "5         0.000038  Hip-Hop  \n",
       "10        0.000058      Pop  \n",
       "140       0.000022     Folk  \n",
       "141       0.000023     Folk  \n",
       "\n",
       "[5 rows x 1186 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = StandardScaler().fit_transform(data_df.drop('genre', axis=1))\n",
    "y = pd.factorize(data_df['genre'])[0]  # Convert genre to numerical labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "X_train_tensor_rnn = X_train_tensor.unsqueeze(1).expand(-1, 10, -1)  # Shape becomes [batch_size, 1, num_features]\n",
    "X_test_tensor_rnn = X_test_tensor.unsqueeze(1).expand(-1, 10, -1)  # Shape becomes [batch_size, 1, num_features]\n",
    "train_dataset_rnn = TensorDataset(X_train_tensor_rnn, y_train_tensor)\n",
    "test_dataset_rnn = TensorDataset(X_test_tensor_rnn, y_test_tensor)\n",
    "train_loader_rnn = DataLoader(train_dataset_rnn, batch_size=256, shuffle=True)\n",
    "test_loader_rnn = DataLoader(test_dataset_rnn, batch_size=256, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.05),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.05),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1D(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(CNN1D, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(32 * (input_dim // 4), 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add a channel dimension\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        return self.fc_layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim=128, num_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, _ = self.rnn(x)\n",
    "        x = self.fc(x[:, -1, :])  # Take the last time step\n",
    "        return x\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim=128, num_layers=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, (hn, cn) = self.lstm(x)\n",
    "        x = self.fc(x[:, -1, :])  # Take the last time step\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, mlp, cnn, rnn, lstm, output_dim):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        self.mlp = mlp\n",
    "        self.cnn = cnn\n",
    "        self.rnn = rnn\n",
    "        self.lstm = lstm\n",
    "        self.fc = nn.Linear(output_dim * 4, output_dim)  # Assuming each model outputs the class probabilities\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out_mlp = self.mlp(x)\n",
    "        out_cnn = self.cnn(x)\n",
    "        out_rnn = self.rnn(x.unsqueeze(1))  # Assume RNN/LSTM expects sequence data\n",
    "        out_lstm = self.lstm(x.unsqueeze(1))\n",
    "        \n",
    "        # Concatenate along the feature dimension\n",
    "        combined = torch.cat((out_mlp, out_cnn, out_rnn, out_lstm), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, device, epochs=100):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    acc=0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        total = correct = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        acc= max(acc,100 * correct / total)\n",
    "\n",
    "        print(f'Epoch {epoch+1}: Accuracy: {100 * correct / total}%')\n",
    "    return(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "num_classes = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Accuracy: 24.262131065532767%\n",
      "Epoch 2: Accuracy: 39.1695847923962%\n",
      "Epoch 3: Accuracy: 43.82191095547774%\n",
      "Epoch 4: Accuracy: 43.621810905452726%\n",
      "Epoch 5: Accuracy: 46.673336668334166%\n",
      "Epoch 6: Accuracy: 47.9239619809905%\n",
      "Epoch 7: Accuracy: 48.924462231115555%\n",
      "Epoch 8: Accuracy: 49.22461230615308%\n",
      "Epoch 9: Accuracy: 49.02451225612806%\n",
      "Epoch 10: Accuracy: 52.02601300650325%\n",
      "Epoch 11: Accuracy: 49.67483741870935%\n",
      "Epoch 12: Accuracy: 49.92496248124062%\n",
      "Epoch 13: Accuracy: 53.076538269134566%\n",
      "Epoch 14: Accuracy: 50.125062531265634%\n",
      "Epoch 15: Accuracy: 51.1255627813907%\n",
      "Epoch 16: Accuracy: 49.77488744372186%\n",
      "Epoch 17: Accuracy: 50.82541270635318%\n",
      "Epoch 18: Accuracy: 50.22511255627814%\n",
      "Epoch 19: Accuracy: 50.42521260630315%\n",
      "Epoch 20: Accuracy: 51.42571285642821%\n",
      "Epoch 21: Accuracy: 53.076538269134566%\n",
      "Epoch 22: Accuracy: 49.82491245622811%\n",
      "Epoch 23: Accuracy: 50.97548774387194%\n",
      "Epoch 24: Accuracy: 51.62581290645323%\n",
      "Epoch 25: Accuracy: 51.37568784392196%\n",
      "Epoch 26: Accuracy: 51.77588794397199%\n",
      "Epoch 27: Accuracy: 51.725862931465734%\n",
      "Epoch 28: Accuracy: 52.02601300650325%\n",
      "Epoch 29: Accuracy: 52.526263131565784%\n",
      "Epoch 30: Accuracy: 51.62581290645323%\n",
      "Epoch 31: Accuracy: 53.87693846923462%\n",
      "Epoch 32: Accuracy: 52.276138069034516%\n",
      "Epoch 33: Accuracy: 52.57628814407204%\n",
      "Epoch 34: Accuracy: 51.77588794397199%\n",
      "Epoch 35: Accuracy: 52.42621310655328%\n",
      "Epoch 36: Accuracy: 50.4752376188094%\n",
      "Epoch 37: Accuracy: 53.726863431715856%\n",
      "Epoch 38: Accuracy: 51.52576288144072%\n",
      "Epoch 39: Accuracy: 52.7263631815908%\n",
      "Epoch 40: Accuracy: 51.37568784392196%\n",
      "Epoch 41: Accuracy: 50.525262631315655%\n",
      "Epoch 42: Accuracy: 52.47623811905953%\n",
      "Epoch 43: Accuracy: 51.57578789394697%\n",
      "Epoch 44: Accuracy: 51.975987993997%\n",
      "Epoch 45: Accuracy: 51.975987993997%\n",
      "Epoch 46: Accuracy: 52.526263131565784%\n",
      "Epoch 47: Accuracy: 52.37618809404702%\n",
      "Epoch 48: Accuracy: 53.27663831915958%\n",
      "Epoch 49: Accuracy: 50.32516258129065%\n",
      "Epoch 50: Accuracy: 51.62581290645323%\n",
      "Epoch 51: Accuracy: 52.526263131565784%\n",
      "Epoch 52: Accuracy: 51.325662831415706%\n",
      "Epoch 53: Accuracy: 52.62631315657829%\n",
      "Epoch 54: Accuracy: 52.62631315657829%\n",
      "Epoch 55: Accuracy: 52.32616308154077%\n",
      "Epoch 56: Accuracy: 50.72536268134067%\n",
      "Epoch 57: Accuracy: 52.676338169084545%\n",
      "Epoch 58: Accuracy: 50.62531265632816%\n",
      "Epoch 59: Accuracy: 52.526263131565784%\n",
      "Epoch 60: Accuracy: 51.92596298149075%\n",
      "Epoch 61: Accuracy: 52.0760380190095%\n",
      "Epoch 62: Accuracy: 50.62531265632816%\n",
      "Epoch 63: Accuracy: 52.276138069034516%\n",
      "Epoch 64: Accuracy: 52.126063031515756%\n",
      "Epoch 65: Accuracy: 52.0760380190095%\n",
      "Epoch 66: Accuracy: 51.82591295647824%\n",
      "Epoch 67: Accuracy: 50.925462731365684%\n",
      "Epoch 68: Accuracy: 51.92596298149075%\n",
      "Epoch 69: Accuracy: 52.02601300650325%\n",
      "Epoch 70: Accuracy: 52.276138069034516%\n",
      "Epoch 71: Accuracy: 52.22611305652826%\n",
      "Epoch 72: Accuracy: 51.875937968984495%\n",
      "Epoch 73: Accuracy: 51.92596298149075%\n",
      "Epoch 74: Accuracy: 53.176588294147074%\n",
      "Epoch 75: Accuracy: 52.02601300650325%\n",
      "Epoch 76: Accuracy: 52.8264132066033%\n",
      "Epoch 77: Accuracy: 51.37568784392196%\n",
      "Epoch 78: Accuracy: 53.176588294147074%\n",
      "Epoch 79: Accuracy: 53.326663331665834%\n",
      "Epoch 80: Accuracy: 51.67583791895948%\n",
      "Epoch 81: Accuracy: 52.22611305652826%\n",
      "Epoch 82: Accuracy: 52.37618809404702%\n",
      "Epoch 83: Accuracy: 52.57628814407204%\n",
      "Epoch 84: Accuracy: 52.32616308154077%\n",
      "Epoch 85: Accuracy: 51.475737868934466%\n",
      "Epoch 86: Accuracy: 52.276138069034516%\n",
      "Epoch 87: Accuracy: 53.12656328164082%\n",
      "Epoch 88: Accuracy: 51.62581290645323%\n",
      "Epoch 89: Accuracy: 51.1255627813907%\n",
      "Epoch 90: Accuracy: 52.7263631815908%\n",
      "Epoch 91: Accuracy: 52.57628814407204%\n",
      "Epoch 92: Accuracy: 52.42621310655328%\n",
      "Epoch 93: Accuracy: 52.676338169084545%\n",
      "Epoch 94: Accuracy: 51.62581290645323%\n",
      "Epoch 95: Accuracy: 51.67583791895948%\n",
      "Epoch 96: Accuracy: 52.32616308154077%\n",
      "Epoch 97: Accuracy: 51.92596298149075%\n",
      "Epoch 98: Accuracy: 53.076538269134566%\n",
      "Epoch 99: Accuracy: 50.72536268134067%\n",
      "Epoch 100: Accuracy: 50.72536268134067%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "53.87693846923462"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp=MLP(input_size,num_classes).to(device)\n",
    "train_model(model_mlp, train_loader, test_loader, device)\n",
    "# 53.87693846923462 entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\divya\\OneDrive\\Documents\\UTAUSTIN\\Semester6\\460j\\460jFinalProject\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Accuracy: 29.31465732866433%\n",
      "Epoch 2: Accuracy: 33.616808404202104%\n",
      "Epoch 3: Accuracy: 35.1175587793897%\n",
      "Epoch 4: Accuracy: 39.41970985492746%\n",
      "Epoch 5: Accuracy: 38.71935967983992%\n",
      "Epoch 6: Accuracy: 39.619809904952476%\n",
      "Epoch 7: Accuracy: 41.620810405202604%\n",
      "Epoch 8: Accuracy: 40.420210105052526%\n",
      "Epoch 9: Accuracy: 42.62131065532766%\n",
      "Epoch 10: Accuracy: 43.52176088044022%\n",
      "Epoch 11: Accuracy: 42.87143571785893%\n",
      "Epoch 12: Accuracy: 44.022011005502755%\n",
      "Epoch 13: Accuracy: 45.37268634317159%\n",
      "Epoch 14: Accuracy: 45.37268634317159%\n",
      "Epoch 15: Accuracy: 45.32266133066533%\n",
      "Epoch 16: Accuracy: 47.473736868434216%\n",
      "Epoch 17: Accuracy: 46.07303651825913%\n",
      "Epoch 18: Accuracy: 46.3231615807904%\n",
      "Epoch 19: Accuracy: 46.523261630815405%\n",
      "Epoch 20: Accuracy: 46.37318659329665%\n",
      "Epoch 21: Accuracy: 47.42371185592796%\n",
      "Epoch 22: Accuracy: 47.473736868434216%\n",
      "Epoch 23: Accuracy: 47.073536768384194%\n",
      "Epoch 24: Accuracy: 46.923461730865434%\n",
      "Epoch 25: Accuracy: 47.873936968484244%\n",
      "Epoch 26: Accuracy: 48.674337168584294%\n",
      "Epoch 27: Accuracy: 46.923461730865434%\n",
      "Epoch 28: Accuracy: 48.37418709354677%\n",
      "Epoch 29: Accuracy: 48.22411205602801%\n",
      "Epoch 30: Accuracy: 47.323661830915455%\n",
      "Epoch 31: Accuracy: 47.62381190595298%\n",
      "Epoch 32: Accuracy: 48.07403701850925%\n",
      "Epoch 33: Accuracy: 47.82391195597799%\n",
      "Epoch 34: Accuracy: 48.524262131065534%\n",
      "Epoch 35: Accuracy: 49.6248124062031%\n",
      "Epoch 36: Accuracy: 48.024012006003%\n",
      "Epoch 37: Accuracy: 48.42421210605303%\n",
      "Epoch 38: Accuracy: 48.47423711855928%\n",
      "Epoch 39: Accuracy: 49.324662331165584%\n",
      "Epoch 40: Accuracy: 48.62431215607804%\n",
      "Epoch 41: Accuracy: 49.5247623811906%\n",
      "Epoch 42: Accuracy: 49.22461230615308%\n",
      "Epoch 43: Accuracy: 49.97498749374687%\n",
      "Epoch 44: Accuracy: 49.474737368684345%\n",
      "Epoch 45: Accuracy: 49.27463731865933%\n",
      "Epoch 46: Accuracy: 49.724862431215605%\n",
      "Epoch 47: Accuracy: 48.82441220610305%\n",
      "Epoch 48: Accuracy: 49.97498749374687%\n",
      "Epoch 49: Accuracy: 49.17458729364682%\n",
      "Epoch 50: Accuracy: 49.474737368684345%\n",
      "Epoch 51: Accuracy: 48.57428714357179%\n",
      "Epoch 52: Accuracy: 50.77538769384692%\n",
      "Epoch 53: Accuracy: 49.5247623811906%\n",
      "Epoch 54: Accuracy: 49.37468734367184%\n",
      "Epoch 55: Accuracy: 49.57478739369685%\n",
      "Epoch 56: Accuracy: 50.07503751875938%\n",
      "Epoch 57: Accuracy: 50.72536268134067%\n",
      "Epoch 58: Accuracy: 49.724862431215605%\n",
      "Epoch 59: Accuracy: 50.82541270635318%\n",
      "Epoch 60: Accuracy: 50.32516258129065%\n",
      "Epoch 61: Accuracy: 49.42471235617809%\n",
      "Epoch 62: Accuracy: 50.42521260630315%\n",
      "Epoch 63: Accuracy: 50.22511255627814%\n",
      "Epoch 64: Accuracy: 50.32516258129065%\n",
      "Epoch 65: Accuracy: 50.17508754377189%\n",
      "Epoch 66: Accuracy: 50.4752376188094%\n",
      "Epoch 67: Accuracy: 48.82441220610305%\n",
      "Epoch 68: Accuracy: 50.57528764382191%\n",
      "Epoch 69: Accuracy: 51.52576288144072%\n",
      "Epoch 70: Accuracy: 49.474737368684345%\n",
      "Epoch 71: Accuracy: 50.17508754377189%\n",
      "Epoch 72: Accuracy: 51.075537768884445%\n",
      "Epoch 73: Accuracy: 51.075537768884445%\n",
      "Epoch 74: Accuracy: 51.27563781890945%\n",
      "Epoch 75: Accuracy: 50.925462731365684%\n",
      "Epoch 76: Accuracy: 50.02501250625313%\n",
      "Epoch 77: Accuracy: 50.42521260630315%\n",
      "Epoch 78: Accuracy: 50.02501250625313%\n",
      "Epoch 79: Accuracy: 50.72536268134067%\n",
      "Epoch 80: Accuracy: 50.125062531265634%\n",
      "Epoch 81: Accuracy: 50.675337668834416%\n",
      "Epoch 82: Accuracy: 50.675337668834416%\n",
      "Epoch 83: Accuracy: 50.57528764382191%\n",
      "Epoch 84: Accuracy: 50.97548774387194%\n",
      "Epoch 85: Accuracy: 51.075537768884445%\n",
      "Epoch 86: Accuracy: 50.57528764382191%\n",
      "Epoch 87: Accuracy: 50.57528764382191%\n",
      "Epoch 88: Accuracy: 50.82541270635318%\n",
      "Epoch 89: Accuracy: 50.62531265632816%\n",
      "Epoch 90: Accuracy: 50.57528764382191%\n",
      "Epoch 91: Accuracy: 50.32516258129065%\n",
      "Epoch 92: Accuracy: 49.57478739369685%\n",
      "Epoch 93: Accuracy: 50.17508754377189%\n",
      "Epoch 94: Accuracy: 50.72536268134067%\n",
      "Epoch 95: Accuracy: 50.525262631315655%\n",
      "Epoch 96: Accuracy: 50.675337668834416%\n",
      "Epoch 97: Accuracy: 51.02551275637819%\n",
      "Epoch 98: Accuracy: 50.925462731365684%\n",
      "Epoch 99: Accuracy: 50.62531265632816%\n",
      "Epoch 100: Accuracy: 49.474737368684345%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51.52576288144072"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn=CNN1D(input_size,num_classes).to(device)\n",
    "train_model(model_cnn, train_loader, test_loader, device) \n",
    "# 51.52576288144072 entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Accuracy: 28.96448224112056%\n",
      "Epoch 2: Accuracy: 32.36618309154577%\n",
      "Epoch 3: Accuracy: 35.41770885442721%\n",
      "Epoch 4: Accuracy: 36.7183591795898%\n",
      "Epoch 5: Accuracy: 39.01950975487744%\n",
      "Epoch 6: Accuracy: 40.020010005002504%\n",
      "Epoch 7: Accuracy: 40.670335167583794%\n",
      "Epoch 8: Accuracy: 41.32066033016508%\n",
      "Epoch 9: Accuracy: 42.57128564282141%\n",
      "Epoch 10: Accuracy: 43.82191095547774%\n",
      "Epoch 11: Accuracy: 44.072036018009%\n",
      "Epoch 12: Accuracy: 44.57228614307154%\n",
      "Epoch 13: Accuracy: 44.47223611805903%\n",
      "Epoch 14: Accuracy: 45.02251125562781%\n",
      "Epoch 15: Accuracy: 45.472736368184094%\n",
      "Epoch 16: Accuracy: 45.472736368184094%\n",
      "Epoch 17: Accuracy: 46.3231615807904%\n",
      "Epoch 18: Accuracy: 46.87343671835918%\n",
      "Epoch 19: Accuracy: 46.57328664332166%\n",
      "Epoch 20: Accuracy: 47.22361180590295%\n",
      "Epoch 21: Accuracy: 47.77388694347174%\n",
      "Epoch 22: Accuracy: 47.67383691845923%\n",
      "Epoch 23: Accuracy: 47.57378689344672%\n",
      "Epoch 24: Accuracy: 47.723861930965484%\n",
      "Epoch 25: Accuracy: 47.9239619809905%\n",
      "Epoch 26: Accuracy: 48.37418709354677%\n",
      "Epoch 27: Accuracy: 48.17408704352176%\n",
      "Epoch 28: Accuracy: 48.57428714357179%\n",
      "Epoch 29: Accuracy: 48.37418709354677%\n",
      "Epoch 30: Accuracy: 48.17408704352176%\n",
      "Epoch 31: Accuracy: 48.57428714357179%\n",
      "Epoch 32: Accuracy: 48.7743871935968%\n",
      "Epoch 33: Accuracy: 47.9239619809905%\n",
      "Epoch 34: Accuracy: 48.62431215607804%\n",
      "Epoch 35: Accuracy: 49.02451225612806%\n",
      "Epoch 36: Accuracy: 48.37418709354677%\n",
      "Epoch 37: Accuracy: 49.02451225612806%\n",
      "Epoch 38: Accuracy: 49.074537268634316%\n",
      "Epoch 39: Accuracy: 48.62431215607804%\n",
      "Epoch 40: Accuracy: 49.22461230615308%\n",
      "Epoch 41: Accuracy: 48.7743871935968%\n",
      "Epoch 42: Accuracy: 48.97448724362181%\n",
      "Epoch 43: Accuracy: 48.8744372186093%\n",
      "Epoch 44: Accuracy: 49.27463731865933%\n",
      "Epoch 45: Accuracy: 48.8744372186093%\n",
      "Epoch 46: Accuracy: 48.924462231115555%\n",
      "Epoch 47: Accuracy: 49.67483741870935%\n",
      "Epoch 48: Accuracy: 49.17458729364682%\n",
      "Epoch 49: Accuracy: 49.57478739369685%\n",
      "Epoch 50: Accuracy: 49.17458729364682%\n",
      "Epoch 51: Accuracy: 49.02451225612806%\n",
      "Epoch 52: Accuracy: 48.82441220610305%\n",
      "Epoch 53: Accuracy: 50.125062531265634%\n",
      "Epoch 54: Accuracy: 49.324662331165584%\n",
      "Epoch 55: Accuracy: 49.42471235617809%\n",
      "Epoch 56: Accuracy: 49.02451225612806%\n",
      "Epoch 57: Accuracy: 49.27463731865933%\n",
      "Epoch 58: Accuracy: 50.17508754377189%\n",
      "Epoch 59: Accuracy: 48.7743871935968%\n",
      "Epoch 60: Accuracy: 49.724862431215605%\n",
      "Epoch 61: Accuracy: 48.924462231115555%\n",
      "Epoch 62: Accuracy: 48.57428714357179%\n",
      "Epoch 63: Accuracy: 49.42471235617809%\n",
      "Epoch 64: Accuracy: 49.02451225612806%\n",
      "Epoch 65: Accuracy: 49.42471235617809%\n",
      "Epoch 66: Accuracy: 48.674337168584294%\n",
      "Epoch 67: Accuracy: 50.125062531265634%\n",
      "Epoch 68: Accuracy: 48.7743871935968%\n",
      "Epoch 69: Accuracy: 48.7743871935968%\n",
      "Epoch 70: Accuracy: 48.47423711855928%\n",
      "Epoch 71: Accuracy: 49.02451225612806%\n",
      "Epoch 72: Accuracy: 48.82441220610305%\n",
      "Epoch 73: Accuracy: 49.77488744372186%\n",
      "Epoch 74: Accuracy: 49.17458729364682%\n",
      "Epoch 75: Accuracy: 49.02451225612806%\n",
      "Epoch 76: Accuracy: 49.22461230615308%\n",
      "Epoch 77: Accuracy: 48.47423711855928%\n",
      "Epoch 78: Accuracy: 48.17408704352176%\n",
      "Epoch 79: Accuracy: 48.62431215607804%\n",
      "Epoch 80: Accuracy: 48.024012006003%\n",
      "Epoch 81: Accuracy: 47.873936968484244%\n",
      "Epoch 82: Accuracy: 48.82441220610305%\n",
      "Epoch 83: Accuracy: 47.473736868434216%\n",
      "Epoch 84: Accuracy: 47.67383691845923%\n",
      "Epoch 85: Accuracy: 48.32416208104052%\n",
      "Epoch 86: Accuracy: 48.57428714357179%\n",
      "Epoch 87: Accuracy: 48.7743871935968%\n",
      "Epoch 88: Accuracy: 47.57378689344672%\n",
      "Epoch 89: Accuracy: 48.024012006003%\n",
      "Epoch 90: Accuracy: 48.62431215607804%\n",
      "Epoch 91: Accuracy: 46.673336668334166%\n",
      "Epoch 92: Accuracy: 47.9239619809905%\n",
      "Epoch 93: Accuracy: 47.473736868434216%\n",
      "Epoch 94: Accuracy: 46.97348674337169%\n",
      "Epoch 95: Accuracy: 47.22361180590295%\n",
      "Epoch 96: Accuracy: 47.12356178089045%\n",
      "Epoch 97: Accuracy: 46.72336168084042%\n",
      "Epoch 98: Accuracy: 46.47323661830915%\n",
      "Epoch 99: Accuracy: 47.42371185592796%\n",
      "Epoch 100: Accuracy: 47.073536768384194%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50.17508754377189"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn=RNN(input_size,num_classes).to(device)\n",
    "train_model(model_rnn, train_loader_rnn, test_loader_rnn, device) \n",
    "#50.17508754377189 entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Accuracy: 26.56328164082041%\n",
      "Epoch 2: Accuracy: 29.864932466233117%\n",
      "Epoch 3: Accuracy: 32.566283141570786%\n",
      "Epoch 4: Accuracy: 34.71735867933967%\n",
      "Epoch 5: Accuracy: 35.91795897948975%\n",
      "Epoch 6: Accuracy: 36.918459229614804%\n",
      "Epoch 7: Accuracy: 38.3191595797899%\n",
      "Epoch 8: Accuracy: 38.76938469234617%\n",
      "Epoch 9: Accuracy: 39.66983491745873%\n",
      "Epoch 10: Accuracy: 40.57028514257129%\n",
      "Epoch 11: Accuracy: 41.77088544272136%\n",
      "Epoch 12: Accuracy: 42.22111055527764%\n",
      "Epoch 13: Accuracy: 42.271135567783894%\n",
      "Epoch 14: Accuracy: 42.271135567783894%\n",
      "Epoch 15: Accuracy: 42.72136068034017%\n",
      "Epoch 16: Accuracy: 43.42171085542771%\n",
      "Epoch 17: Accuracy: 43.67183591795898%\n",
      "Epoch 18: Accuracy: 44.17208604302151%\n",
      "Epoch 19: Accuracy: 44.17208604302151%\n",
      "Epoch 20: Accuracy: 44.422211105552776%\n",
      "Epoch 21: Accuracy: 45.12256128064032%\n",
      "Epoch 22: Accuracy: 45.52276138069035%\n",
      "Epoch 23: Accuracy: 45.42271135567784%\n",
      "Epoch 24: Accuracy: 45.92296148074037%\n",
      "Epoch 25: Accuracy: 46.17308654327164%\n",
      "Epoch 26: Accuracy: 46.87343671835918%\n",
      "Epoch 27: Accuracy: 46.47323661830915%\n",
      "Epoch 28: Accuracy: 46.423211605802905%\n",
      "Epoch 29: Accuracy: 46.57328664332166%\n",
      "Epoch 30: Accuracy: 46.87343671835918%\n",
      "Epoch 31: Accuracy: 47.1735867933967%\n",
      "Epoch 32: Accuracy: 48.274137068534266%\n",
      "Epoch 33: Accuracy: 48.17408704352176%\n",
      "Epoch 34: Accuracy: 47.82391195597799%\n",
      "Epoch 35: Accuracy: 47.97398699349675%\n",
      "Epoch 36: Accuracy: 47.62381190595298%\n",
      "Epoch 37: Accuracy: 48.674337168584294%\n",
      "Epoch 38: Accuracy: 48.524262131065534%\n",
      "Epoch 39: Accuracy: 48.82441220610305%\n",
      "Epoch 40: Accuracy: 48.37418709354677%\n",
      "Epoch 41: Accuracy: 49.27463731865933%\n",
      "Epoch 42: Accuracy: 49.27463731865933%\n",
      "Epoch 43: Accuracy: 48.924462231115555%\n",
      "Epoch 44: Accuracy: 48.924462231115555%\n",
      "Epoch 45: Accuracy: 49.57478739369685%\n",
      "Epoch 46: Accuracy: 49.074537268634316%\n",
      "Epoch 47: Accuracy: 49.6248124062031%\n",
      "Epoch 48: Accuracy: 49.17458729364682%\n",
      "Epoch 49: Accuracy: 49.17458729364682%\n",
      "Epoch 50: Accuracy: 48.57428714357179%\n",
      "Epoch 51: Accuracy: 49.074537268634316%\n",
      "Epoch 52: Accuracy: 48.97448724362181%\n",
      "Epoch 53: Accuracy: 48.97448724362181%\n",
      "Epoch 54: Accuracy: 49.324662331165584%\n",
      "Epoch 55: Accuracy: 48.97448724362181%\n",
      "Epoch 56: Accuracy: 49.67483741870935%\n",
      "Epoch 57: Accuracy: 48.62431215607804%\n",
      "Epoch 58: Accuracy: 49.42471235617809%\n",
      "Epoch 59: Accuracy: 49.02451225612806%\n",
      "Epoch 60: Accuracy: 48.62431215607804%\n",
      "Epoch 61: Accuracy: 49.17458729364682%\n",
      "Epoch 62: Accuracy: 48.8744372186093%\n",
      "Epoch 63: Accuracy: 49.22461230615308%\n",
      "Epoch 64: Accuracy: 48.924462231115555%\n",
      "Epoch 65: Accuracy: 48.7743871935968%\n",
      "Epoch 66: Accuracy: 49.22461230615308%\n",
      "Epoch 67: Accuracy: 48.8744372186093%\n",
      "Epoch 68: Accuracy: 48.97448724362181%\n",
      "Epoch 69: Accuracy: 49.27463731865933%\n",
      "Epoch 70: Accuracy: 48.7743871935968%\n",
      "Epoch 71: Accuracy: 48.57428714357179%\n",
      "Epoch 72: Accuracy: 49.12456228114057%\n",
      "Epoch 73: Accuracy: 48.57428714357179%\n",
      "Epoch 74: Accuracy: 49.37468734367184%\n",
      "Epoch 75: Accuracy: 49.02451225612806%\n",
      "Epoch 76: Accuracy: 49.42471235617809%\n",
      "Epoch 77: Accuracy: 49.12456228114057%\n",
      "Epoch 78: Accuracy: 48.7743871935968%\n",
      "Epoch 79: Accuracy: 48.72436218109055%\n",
      "Epoch 80: Accuracy: 48.37418709354677%\n",
      "Epoch 81: Accuracy: 49.12456228114057%\n",
      "Epoch 82: Accuracy: 49.02451225612806%\n",
      "Epoch 83: Accuracy: 49.22461230615308%\n",
      "Epoch 84: Accuracy: 49.074537268634316%\n",
      "Epoch 85: Accuracy: 49.02451225612806%\n",
      "Epoch 86: Accuracy: 49.02451225612806%\n",
      "Epoch 87: Accuracy: 48.72436218109055%\n",
      "Epoch 88: Accuracy: 49.57478739369685%\n",
      "Epoch 89: Accuracy: 48.62431215607804%\n",
      "Epoch 90: Accuracy: 49.02451225612806%\n",
      "Epoch 91: Accuracy: 49.37468734367184%\n",
      "Epoch 92: Accuracy: 48.57428714357179%\n",
      "Epoch 93: Accuracy: 48.82441220610305%\n",
      "Epoch 94: Accuracy: 49.324662331165584%\n",
      "Epoch 95: Accuracy: 48.674337168584294%\n",
      "Epoch 96: Accuracy: 49.37468734367184%\n",
      "Epoch 97: Accuracy: 48.924462231115555%\n",
      "Epoch 98: Accuracy: 48.024012006003%\n",
      "Epoch 99: Accuracy: 48.274137068534266%\n",
      "Epoch 100: Accuracy: 49.074537268634316%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49.67483741870935"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm=LSTM(input_size,num_classes).to(device)\n",
    "train_model(model_lstm, train_loader_rnn, test_loader_rnn, device) \n",
    "#49.67483741870935 entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Accuracy: 29.514757378689346%\n",
      "Epoch 2: Accuracy: 35.41770885442721%\n",
      "Epoch 3: Accuracy: 39.01950975487744%\n",
      "Epoch 4: Accuracy: 40.72036018009005%\n",
      "Epoch 5: Accuracy: 43.82191095547774%\n",
      "Epoch 6: Accuracy: 44.77238619309655%\n",
      "Epoch 7: Accuracy: 46.023011505752876%\n",
      "Epoch 8: Accuracy: 47.323661830915455%\n",
      "Epoch 9: Accuracy: 47.42371185592796%\n",
      "Epoch 10: Accuracy: 48.37418709354677%\n",
      "Epoch 11: Accuracy: 50.02501250625313%\n",
      "Epoch 12: Accuracy: 46.97348674337169%\n",
      "Epoch 13: Accuracy: 51.82591295647824%\n",
      "Epoch 14: Accuracy: 49.77488744372186%\n",
      "Epoch 15: Accuracy: 51.92596298149075%\n",
      "Epoch 16: Accuracy: 50.22511255627814%\n",
      "Epoch 17: Accuracy: 50.675337668834416%\n",
      "Epoch 18: Accuracy: 50.17508754377189%\n",
      "Epoch 19: Accuracy: 50.675337668834416%\n",
      "Epoch 20: Accuracy: 52.32616308154077%\n",
      "Epoch 21: Accuracy: 51.475737868934466%\n",
      "Epoch 22: Accuracy: 51.725862931465734%\n",
      "Epoch 23: Accuracy: 51.475737868934466%\n",
      "Epoch 24: Accuracy: 50.62531265632816%\n",
      "Epoch 25: Accuracy: 50.77538769384692%\n",
      "Epoch 26: Accuracy: 51.27563781890945%\n",
      "Epoch 27: Accuracy: 51.77588794397199%\n",
      "Epoch 28: Accuracy: 52.126063031515756%\n",
      "Epoch 29: Accuracy: 53.62681340670335%\n",
      "Epoch 30: Accuracy: 51.82591295647824%\n",
      "Epoch 31: Accuracy: 51.075537768884445%\n",
      "Epoch 32: Accuracy: 52.47623811905953%\n",
      "Epoch 33: Accuracy: 52.02601300650325%\n",
      "Epoch 34: Accuracy: 48.924462231115555%\n",
      "Epoch 35: Accuracy: 51.2256128064032%\n",
      "Epoch 36: Accuracy: 50.82541270635318%\n",
      "Epoch 37: Accuracy: 51.42571285642821%\n",
      "Epoch 38: Accuracy: 51.37568784392196%\n",
      "Epoch 39: Accuracy: 53.176588294147074%\n",
      "Epoch 40: Accuracy: 51.77588794397199%\n",
      "Epoch 41: Accuracy: 51.2256128064032%\n",
      "Epoch 42: Accuracy: 50.62531265632816%\n",
      "Epoch 43: Accuracy: 51.67583791895948%\n",
      "Epoch 44: Accuracy: 51.92596298149075%\n",
      "Epoch 45: Accuracy: 52.37618809404702%\n",
      "Epoch 46: Accuracy: 50.42521260630315%\n",
      "Epoch 47: Accuracy: 49.97498749374687%\n",
      "Epoch 48: Accuracy: 52.126063031515756%\n",
      "Epoch 49: Accuracy: 51.57578789394697%\n",
      "Epoch 50: Accuracy: 51.57578789394697%\n",
      "Epoch 51: Accuracy: 50.72536268134067%\n",
      "Epoch 52: Accuracy: 51.875937968984495%\n",
      "Epoch 53: Accuracy: 51.42571285642821%\n",
      "Epoch 54: Accuracy: 50.525262631315655%\n",
      "Epoch 55: Accuracy: 50.675337668834416%\n",
      "Epoch 56: Accuracy: 51.77588794397199%\n",
      "Epoch 57: Accuracy: 51.67583791895948%\n",
      "Epoch 58: Accuracy: 51.02551275637819%\n",
      "Epoch 59: Accuracy: 51.475737868934466%\n",
      "Epoch 60: Accuracy: 50.72536268134067%\n",
      "Epoch 61: Accuracy: 49.22461230615308%\n",
      "Epoch 62: Accuracy: 51.57578789394697%\n",
      "Epoch 63: Accuracy: 51.92596298149075%\n",
      "Epoch 64: Accuracy: 52.32616308154077%\n",
      "Epoch 65: Accuracy: 51.1255627813907%\n",
      "Epoch 66: Accuracy: 51.1255627813907%\n",
      "Epoch 67: Accuracy: 51.325662831415706%\n",
      "Epoch 68: Accuracy: 50.925462731365684%\n",
      "Epoch 69: Accuracy: 51.27563781890945%\n",
      "Epoch 70: Accuracy: 50.77538769384692%\n",
      "Epoch 71: Accuracy: 51.52576288144072%\n",
      "Epoch 72: Accuracy: 51.37568784392196%\n",
      "Epoch 73: Accuracy: 50.82541270635318%\n",
      "Epoch 74: Accuracy: 51.27563781890945%\n",
      "Epoch 75: Accuracy: 51.77588794397199%\n",
      "Epoch 76: Accuracy: 51.475737868934466%\n",
      "Epoch 77: Accuracy: 50.675337668834416%\n",
      "Epoch 78: Accuracy: 51.02551275637819%\n",
      "Epoch 79: Accuracy: 51.82591295647824%\n",
      "Epoch 80: Accuracy: 51.27563781890945%\n",
      "Epoch 81: Accuracy: 50.82541270635318%\n",
      "Epoch 82: Accuracy: 51.075537768884445%\n",
      "Epoch 83: Accuracy: 51.82591295647824%\n",
      "Epoch 84: Accuracy: 51.57578789394697%\n",
      "Epoch 85: Accuracy: 51.77588794397199%\n",
      "Epoch 86: Accuracy: 50.3751875937969%\n",
      "Epoch 87: Accuracy: 52.276138069034516%\n",
      "Epoch 88: Accuracy: 51.52576288144072%\n",
      "Epoch 89: Accuracy: 51.42571285642821%\n",
      "Epoch 90: Accuracy: 51.62581290645323%\n",
      "Epoch 91: Accuracy: 53.476738369184595%\n",
      "Epoch 92: Accuracy: 52.276138069034516%\n",
      "Epoch 93: Accuracy: 52.97648824412206%\n",
      "Epoch 94: Accuracy: 52.526263131565784%\n",
      "Epoch 95: Accuracy: 51.27563781890945%\n",
      "Epoch 96: Accuracy: 51.82591295647824%\n",
      "Epoch 97: Accuracy: 51.52576288144072%\n",
      "Epoch 98: Accuracy: 52.42621310655328%\n",
      "Epoch 99: Accuracy: 52.22611305652826%\n",
      "Epoch 100: Accuracy: 52.126063031515756%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "53.62681340670335"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn_2=CNN1D(input_size,num_classes).to(device)\n",
    "model_mlp_2=MLP(input_size,num_classes).to(device)\n",
    "model_rnn_2=RNN(input_size,num_classes).to(device)\n",
    "model_lstm_2=LSTM(input_size,num_classes).to(device)\n",
    "\n",
    "model_ens=EnsembleModel(mlp=model_mlp_2,cnn=model_cnn_2,rnn=model_rnn_2,lstm=model_lstm_2,output_dim=num_classes).to(device)\n",
    "train_model(model_ens, train_loader, test_loader, device)\n",
    "# 53.62681340670335 accuracy entropy loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
