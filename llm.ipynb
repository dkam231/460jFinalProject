{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to c:\\users\\divya\\appdata\\local\\temp\\pip-req-build-bsl3knqf\n",
      "  Resolved https://github.com/huggingface/transformers to commit 12c39e5693f7223be162a1e84de026a6545029eb\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: filelock in c:\\users\\divya\\onedrive\\documents\\utaustin\\semester6\\460j\\460jfinalproject\\.venv\\lib\\site-packages (from transformers==4.41.0.dev0) (3.13.4)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers==4.41.0.dev0)\n",
      "  Using cached huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\divya\\onedrive\\documents\\utaustin\\semester6\\460j\\460jfinalproject\\.venv\\lib\\site-packages (from transformers==4.41.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\divya\\onedrive\\documents\\utaustin\\semester6\\460j\\460jfinalproject\\.venv\\lib\\site-packages (from transformers==4.41.0.dev0) (24.0)\n",
      "Collecting pyyaml>=5.1 (from transformers==4.41.0.dev0)\n",
      "  Using cached PyYAML-6.0.1-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\divya\\onedrive\\documents\\utaustin\\semester6\\460j\\460jfinalproject\\.venv\\lib\\site-packages (from transformers==4.41.0.dev0) (2024.4.16)\n",
      "Requirement already satisfied: requests in c:\\users\\divya\\onedrive\\documents\\utaustin\\semester6\\460j\\460jfinalproject\\.venv\\lib\\site-packages (from transformers==4.41.0.dev0) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.41.0.dev0)\n",
      "  Using cached tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.41.0.dev0)\n",
      "  Using cached safetensors-0.4.3-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers==4.41.0.dev0)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\divya\\onedrive\\documents\\utaustin\\semester6\\460j\\460jfinalproject\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.41.0.dev0) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\divya\\onedrive\\documents\\utaustin\\semester6\\460j\\460jfinalproject\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.41.0.dev0) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\divya\\onedrive\\documents\\utaustin\\semester6\\460j\\460jfinalproject\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers==4.41.0.dev0) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\divya\\onedrive\\documents\\utaustin\\semester6\\460j\\460jfinalproject\\.venv\\lib\\site-packages (from requests->transformers==4.41.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\divya\\onedrive\\documents\\utaustin\\semester6\\460j\\460jfinalproject\\.venv\\lib\\site-packages (from requests->transformers==4.41.0.dev0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\divya\\onedrive\\documents\\utaustin\\semester6\\460j\\460jfinalproject\\.venv\\lib\\site-packages (from requests->transformers==4.41.0.dev0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\divya\\onedrive\\documents\\utaustin\\semester6\\460j\\460jfinalproject\\.venv\\lib\\site-packages (from requests->transformers==4.41.0.dev0) (2024.2.2)\n",
      "Using cached huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "Using cached PyYAML-6.0.1-cp311-cp311-win_amd64.whl (144 kB)\n",
      "Using cached safetensors-0.4.3-cp311-none-win_amd64.whl (287 kB)\n",
      "Using cached tokenizers-0.19.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml): started\n",
      "  Building wheel for transformers (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for transformers: filename=transformers-4.41.0.dev0-py3-none-any.whl size=9045141 sha256=4791d4863632fb03e53f4ab91fc4a58c1f4037ba7cf36931e2fc394df2b52255\n",
      "  Stored in directory: C:\\Users\\divya\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-tr1pl2gf\\wheels\\04\\a3\\f1\\b88775f8e1665827525b19ac7590250f1038d947067beba9fb\n",
      "Successfully built transformers\n",
      "Installing collected packages: tqdm, safetensors, pyyaml, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.22.2 pyyaml-6.0.1 safetensors-0.4.3 tokenizers-0.19.1 tqdm-4.66.2 transformers-4.41.0.dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers 'C:\\Users\\divya\\AppData\\Local\\Temp\\pip-req-build-bsl3knqf'\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir=\"C:/Users/divya/OneDrive/Documents/UTAUSTIN/Semester 6/460j/final_project_data/fma_small\"\n",
    "# file_path=\"C:/Users/divya/OneDrive/Documents/UTAUSTIN/Semester 6/460j/final_project_data/fma_small/000/000002.mp3\"\n",
    "train_path = 'C:/Users/divya/OneDrive/Documents/UTAUSTIN/Semester 6/460j/460jFinalProject/extracted_features_combined.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>1176</th>\n",
       "      <th>1177</th>\n",
       "      <th>1178</th>\n",
       "      <th>1179</th>\n",
       "      <th>1180</th>\n",
       "      <th>1181</th>\n",
       "      <th>1182</th>\n",
       "      <th>1183</th>\n",
       "      <th>1184</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-122.713936</td>\n",
       "      <td>117.760094</td>\n",
       "      <td>-42.334183</td>\n",
       "      <td>38.061005</td>\n",
       "      <td>-23.012323</td>\n",
       "      <td>23.920383</td>\n",
       "      <td>-11.944865</td>\n",
       "      <td>13.687291</td>\n",
       "      <td>-7.294582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>-162.232422</td>\n",
       "      <td>131.435989</td>\n",
       "      <td>-18.426781</td>\n",
       "      <td>51.631371</td>\n",
       "      <td>-15.444844</td>\n",
       "      <td>23.860094</td>\n",
       "      <td>-7.867664</td>\n",
       "      <td>10.686234</td>\n",
       "      <td>-0.314591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>-75.631538</td>\n",
       "      <td>154.537613</td>\n",
       "      <td>-63.849487</td>\n",
       "      <td>22.506426</td>\n",
       "      <td>2.425359</td>\n",
       "      <td>10.459981</td>\n",
       "      <td>-13.007332</td>\n",
       "      <td>9.818939</td>\n",
       "      <td>-7.640783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140</td>\n",
       "      <td>-322.997864</td>\n",
       "      <td>133.684906</td>\n",
       "      <td>15.497437</td>\n",
       "      <td>54.755615</td>\n",
       "      <td>8.718211</td>\n",
       "      <td>37.022747</td>\n",
       "      <td>-2.116411</td>\n",
       "      <td>15.265619</td>\n",
       "      <td>6.175477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>Folk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141</td>\n",
       "      <td>-253.314560</td>\n",
       "      <td>157.769379</td>\n",
       "      <td>-6.081675</td>\n",
       "      <td>26.920168</td>\n",
       "      <td>6.813843</td>\n",
       "      <td>15.842272</td>\n",
       "      <td>-12.930041</td>\n",
       "      <td>10.373278</td>\n",
       "      <td>-0.609945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>Folk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id           0           1          2          3          4  \\\n",
       "0         2 -122.713936  117.760094 -42.334183  38.061005 -23.012323   \n",
       "1         5 -162.232422  131.435989 -18.426781  51.631371 -15.444844   \n",
       "2        10  -75.631538  154.537613 -63.849487  22.506426   2.425359   \n",
       "3       140 -322.997864  133.684906  15.497437  54.755615   8.718211   \n",
       "4       141 -253.314560  157.769379  -6.081675  26.920168   6.813843   \n",
       "\n",
       "           5          6          7         8  ...      1176      1177  \\\n",
       "0  23.920383 -11.944865  13.687291 -7.294582  ...  0.000032  0.000033   \n",
       "1  23.860094  -7.867664  10.686234 -0.314591  ...  0.000039  0.000041   \n",
       "2  10.459981 -13.007332   9.818939 -7.640783  ...  0.000056  0.000066   \n",
       "3  37.022747  -2.116411  15.265619  6.175477  ...  0.000041  0.000035   \n",
       "4  15.842272 -12.930041  10.373278 -0.609945  ...  0.000029  0.000025   \n",
       "\n",
       "       1178      1179      1180      1181      1182      1183      1184  \\\n",
       "0  0.000039  0.000048  0.000078  0.000110  0.000089  0.000050  0.000029   \n",
       "1  0.000060  0.000092  0.000102  0.000146  0.000153  0.000072  0.000038   \n",
       "2  0.000069  0.000083  0.000095  0.000103  0.000103  0.000072  0.000058   \n",
       "3  0.000031  0.000038  0.000050  0.000052  0.000034  0.000024  0.000022   \n",
       "4  0.000026  0.000048  0.000095  0.000081  0.000036  0.000029  0.000023   \n",
       "\n",
       "     genre  \n",
       "0  Hip-Hop  \n",
       "1  Hip-Hop  \n",
       "2      Pop  \n",
       "3     Folk  \n",
       "4     Folk  \n",
       "\n",
       "[5 rows x 1187 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(data_df.drop('genre', axis=1))\n",
    "y = pd.factorize(data_df['genre'])[0]  # Convert genre to numerical labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dataset class\n",
    "class GenreDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'input_ids': self.features[idx], 'labels': self.labels[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_dataset = GenreDataset(X_train, y_train)\n",
    "test_dataset = GenreDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, dropout, forward_expansion):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=heads, dropout=dropout)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, forward_expansion * embed_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(forward_expansion * embed_size, embed_size),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, value, key, query, mask):\n",
    "        attention = self.attention(query, key, value, attn_mask=mask)[0]\n",
    "        x = self.dropout(self.norm1(attention + query))\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "        return out\n",
    "\n",
    "class CustomBERT(nn.Module):\n",
    "    def __init__(self, embed_size, num_layers, heads, device, forward_expansion, dropout, num_classes):\n",
    "        super(CustomBERT, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.device = device\n",
    "        self.layers = nn.ModuleList(\n",
    "            [TransformerBlock(embed_size, heads, dropout, forward_expansion) for _ in range(num_layers)]\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(embed_size, 8)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        out = x\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, out, out, mask)\n",
    "        out = out.mean(dim=1)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc_out(out)\n",
    "        return self.sig(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomBERT(\n",
       "  (layers): ModuleList(\n",
       "    (0-7): 8 x TransformerBlock(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=1186, out_features=1186, bias=True)\n",
       "      )\n",
       "      (norm1): LayerNorm((1186,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((1186,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): Sequential(\n",
       "        (0): Linear(in_features=1186, out_features=4744, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=4744, out_features=1186, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc_out): Linear(in_features=1186, out_features=8, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constants\n",
    "embed_size = 1186  # Size of each embedding vector\n",
    "num_layers = 8    # Number of transformer blocks\n",
    "heads = 2         # Number of heads in multi-head attention mechanism\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "forward_expansion = 4\n",
    "dropout = 0.1\n",
    "num_classes = 8   # Assuming 8 genre classes\n",
    "max_len = 1186    # Maximum length of the input\n",
    "\n",
    "\n",
    "model = CustomBERT(embed_size, num_layers, heads, device, forward_expansion, dropout, num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x256 and 1186x8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m data, targets \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Assuming no mask is needed\u001b[39;00m\n\u001b[0;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\divya\\OneDrive\\Documents\\UTAUSTIN\\Semester 6\\460j\\460jFinalProject\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\divya\\OneDrive\\Documents\\UTAUSTIN\\Semester 6\\460j\\460jFinalProject\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[78], line 41\u001b[0m, in \u001b[0;36mCustomBERT.forward\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m     39\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     40\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(out)\n\u001b[1;32m---> 41\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msig(out)\n",
      "File \u001b[1;32mc:\\Users\\divya\\OneDrive\\Documents\\UTAUSTIN\\Semester 6\\460j\\460jFinalProject\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\divya\\OneDrive\\Documents\\UTAUSTIN\\Semester 6\\460j\\460jFinalProject\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\divya\\OneDrive\\Documents\\UTAUSTIN\\Semester 6\\460j\\460jFinalProject\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x256 and 1186x8)"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 256\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 10\n",
    "\n",
    "# Prepare DataLoader utilities\n",
    "def batch_loader(X, y, batch_size=32):\n",
    "    for i in range(0, len(X) - batch_size + 1, batch_size):\n",
    "        indices = slice(i, i + batch_size)\n",
    "        yield torch.tensor(X[indices], dtype=torch.float32), torch.tensor(y[indices], dtype=torch.long)\n",
    "\n",
    "# Optimizer and Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    X_train, y_train = shuffle(X_train, y_train)  # Shuffle the data each epoch\n",
    "    for data, targets in batch_loader(X_train, y_train, batch_size):\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(data, mask=None)  # Assuming no mask is needed\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "    \n",
    "    # Print epoch information\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/total:.4f}, Accuracy: {train_acc:.2f}%')\n",
    "\n",
    "# Validation loop\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, targets in batch_loader(X_test, y_test, batch_size):\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        outputs = model(data, mask=None)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "    \n",
    "    val_acc = 100 * correct / total\n",
    "    print(f'Validation Accuracy: {val_acc:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
