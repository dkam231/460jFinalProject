{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1Co3Nau-BzF"
      },
      "source": [
        "## Combined XGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XdGuDgxd6Cqd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "\n",
        "data = pd.read_csv('extracted_features_combined.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JswPLoXq79p7"
      },
      "outputs": [],
      "source": [
        "X = data.iloc[:, :-1]  # Features (all columns except the last one)\n",
        "y = data.iloc[:, -1]   # Labels (the last column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IN2Bsdiq8DkM"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-fW95Xu7b-m"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "model = xgb.XGBClassifier(subsample = 1.0, n_estimators = 400, max_depth = 7, learning_rate = 0.05, gamma = 0, colsample_bytree = 0.5, n_jobs = -1)\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Make probability predictions on the testing data\n",
        "y_prob = model.predict_proba(X_test)\n",
        "\n",
        "# Calculate AUC score\n",
        "auc_score = roc_auc_score(y_test, y_prob, multi_class='ovr')\n",
        "print(\"AUC Score:\", auc_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-vDsU3lMCMTh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67dbb95f-ecad-4128-fa79-71751a2b1c92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5927469779074614\n",
            "AUC Score: 0.8995339662168482\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "model = xgb.XGBClassifier()\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Make probability predictions on the testing data\n",
        "y_prob = model.predict_proba(X_test)\n",
        "\n",
        "# Calculate AUC score\n",
        "auc_score = roc_auc_score(y_test, y_prob, multi_class='ovr')\n",
        "print(\"AUC Score:\", auc_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naUrw5buDrNd"
      },
      "source": [
        "Basic XGBoost of extracted_features_combined\n",
        "\n",
        "Accuracy: 0.6053783614759225\n",
        "\n",
        "AUC Score: 0.902076825823791"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsOMaogNOmBk"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the number of top features to display\n",
        "top_n = 50  # Adjust this number as needed\n",
        "\n",
        "# Get the top N feature names and their importance scores\n",
        "top_features = features[:top_n]\n",
        "top_importance_scores = importance_scores[:top_n]\n",
        "\n",
        "# Plot the top N feature importance scores\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.barh(top_features, top_importance_scores, color='skyblue')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.ylabel('Features')\n",
        "plt.title('Top {} Feature Importance Scores'.format(top_n))\n",
        "plt.gca().invert_yaxis()  # Invert y-axis to display highest importance at the top\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iZE2ouRPm8Z"
      },
      "outputs": [],
      "source": [
        "# Find features with 0 importance\n",
        "zero_importance_features = [feature for feature, importance in sorted_feature_importance if importance == 0]\n",
        "\n",
        "# Print features with 0 importance\n",
        "print(\"Features with 0 importance:\")\n",
        "for feature in zero_importance_features:\n",
        "    print(feature)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUjElgPEHrKh"
      },
      "source": [
        "## TESTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dem-VVtO8GZ8",
        "outputId": "7dc31874-ccd9-404a-eeb9-94abfdf5eb55"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01}\n",
            "Best AUC Score: 0.868186778204652\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "model = xgb.XGBClassifier()\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define the parameter distributions for RandomizedSearchCV\n",
        "param_distributions = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.1, 0.01, 0.001]\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_distributions, n_iter=10, cv=3, scoring='roc_auc', n_jobs=-1)\n",
        "\n",
        "# Fit the randomized search to the data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = random_search.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "# Get the best estimator\n",
        "best_estimator = random_search.best_estimator_\n",
        "\n",
        "# Make predictions on the testing data using the best estimator\n",
        "y_prob_best = best_estimator.predict_proba(X_test)\n",
        "\n",
        "# Calculate AUC score using the best estimator\n",
        "auc_score_best = roc_auc_score(y_test, y_prob_best, multi_class='ovr')\n",
        "print(\"Best AUC Score:\", auc_score_best)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvLdbUoW-IhX"
      },
      "source": [
        "## Wav XGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BjbRi0h-KH_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "\n",
        "data = pd.read_csv('extracted_features_wav2vec.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDVo4ohg-St1"
      },
      "outputs": [],
      "source": [
        "X = data.iloc[:, :-1]  # Features (all columns except the last one)\n",
        "y = data.iloc[:, -1]   # Labels (the last column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVf3-qpQ-T5Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oTrzP2A-VIT",
        "outputId": "6bd400da-ed67-461a-9d5f-a727d983cf6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.4675\n",
            "AUC Score: 0.8180124506258732\n"
          ]
        }
      ],
      "source": [
        "# Define the XGBoost model\n",
        "model = xgb.XGBClassifier()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Make probability predictions on the testing data\n",
        "y_prob = model.predict_proba(X_test)\n",
        "\n",
        "# Calculate AUC score\n",
        "auc_score = roc_auc_score(y_test, y_prob, multi_class='ovr')\n",
        "print(\"AUC Score:\", auc_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGBb8_CiFJSY"
      },
      "source": [
        "Basic XGBoost of wav2vec\n",
        "\n",
        "Accuracy: 0.4675\n",
        "\n",
        "AUC Score: 0.8180124506258732"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFBNDpnb4D2w"
      },
      "source": [
        "## dft_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdJX7gPd4HI3",
        "outputId": "b6664672-8c63-4855-8e3d-bd710d2ded13"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.1}\n",
            "Best AUC Score: 0.8510608477570046\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "\n",
        "data = pd.read_csv('dft_features.csv')\n",
        "X = data.iloc[:, 2:]  # Features (all columns except the first two)\n",
        "y = data.iloc[:, 1]   # Labels (the second column)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "model = xgb.XGBClassifier()\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Define the parameter distributions for RandomizedSearchCV\n",
        "param_distributions = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.1, 0.01, 0.001]\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_distributions, n_iter=10, cv=3, scoring='roc_auc', n_jobs=-1)\n",
        "\n",
        "# Fit the randomized search to the data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = random_search.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "# Get the best estimator\n",
        "best_estimator = random_search.best_estimator_\n",
        "\n",
        "# Make predictions on the testing data using the best estimator\n",
        "y_prob_best = best_estimator.predict_proba(X_test)\n",
        "\n",
        "# Calculate AUC score using the best estimator\n",
        "auc_score_best = roc_auc_score(y_test, y_prob_best, multi_class='ovr')\n",
        "print(\"Best AUC Score:\", auc_score_best)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtATRGv-EFsB",
        "outputId": "f3f02647-5d03-42ef-afb1-8a5dd4947d42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.4978111319574734\n",
            "AUC Score: 0.8456550929359332\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "\n",
        "data = pd.read_csv('dft_features.csv')\n",
        "X = data.iloc[:, 2:]  # Features (all columns except the first two)\n",
        "y = data.iloc[:, 1]   # Labels (the second column)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "model = xgb.XGBClassifier()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Make probability predictions on the testing data\n",
        "y_prob = model.predict_proba(X_test)\n",
        "\n",
        "# Calculate AUC score\n",
        "auc_score = roc_auc_score(y_test, y_prob, multi_class='ovr')\n",
        "print(\"AUC Score:\", auc_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZHATc3nGO2g"
      },
      "source": [
        "Basic XGBoost of dft_features\n",
        "\n",
        "Accuracy: 0.4978111319574734\n",
        "\n",
        "AUC Score: 0.8456550929359332"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaZ7PsFUW2hz"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sb8MlT5mW2Fs"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Initialize KNN classifier\n",
        "knn = KNeighborsClassifier(n_neighbors = 8)\n",
        "\n",
        "# Train the KNN classifier\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred_knn_top_8 = knn.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_knn_top_8 = accuracy_score(y_test, y_pred_knn_top_8)\n",
        "print(\"Accuracy of KNN with top 8 features:\", accuracy_knn_top_8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4ScwjZKoIeV"
      },
      "source": [
        "## Feature Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKMqLL_LoKHR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUR9p_iqoNsm"
      },
      "outputs": [],
      "source": [
        "data_df =pd.read_csv(\"extracted_features_combined.csv\")\n",
        "\n",
        "X = data_df.drop(['track_id','genre'], axis=1)  # Drop the 'Id' column and target variable 'Y' to create feature matrix X\n",
        "y = data_df['genre']  # Target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W_-DQegoVTS",
        "outputId": "acfd21d0-2f3a-4f38-ce84-a4aa665369d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       float64\n",
            "1       float64\n",
            "2       float64\n",
            "3       float64\n",
            "4       float64\n",
            "         ...   \n",
            "1180    float64\n",
            "1181    float64\n",
            "1182    float64\n",
            "1183    float64\n",
            "1184    float64\n",
            "Length: 1185, dtype: object\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "# Encoding the target variable if it's categorical\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ensure 'Genre' is the target and it's not part of X_train\n",
        "if 'genre' in X_train.columns:\n",
        "    X_train = X_train.drop('genre', axis=1)\n",
        "if 'genre' in X_val.columns:\n",
        "    X_test = X_val.drop('genre', axis=1)\n",
        "\n",
        "# Check data types\n",
        "print(X_train.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap3omFK3ohvN",
        "outputId": "c97a292b-dcd8-41fc-a5a4-c1980429a96f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting CatBoost\n",
            "  Using cached catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from CatBoost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from CatBoost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from CatBoost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from CatBoost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from CatBoost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from CatBoost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from CatBoost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->CatBoost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->CatBoost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->CatBoost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->CatBoost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->CatBoost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->CatBoost) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->CatBoost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->CatBoost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->CatBoost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->CatBoost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->CatBoost) (8.2.3)\n",
            "Installing collected packages: CatBoost\n",
            "Successfully installed CatBoost-1.2.5\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ]
        }
      ],
      "source": [
        "!pip install CatBoost\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier  # Import CatBoost\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# Define final estimator\n",
        "final_estimator = LogisticRegression(random_state=42)\n",
        "\n",
        "# Initialize the classifiers\n",
        "catboost_clf = CatBoostClassifier(verbose=0, random_state=42)  # Initialize CatBoost, turn off verbose output\n",
        "adaboost_clf = AdaBoostClassifier(n_estimators=100)\n",
        "\n",
        "# Define base models\n",
        "estimators = [\n",
        "    ('catboost', catboost_clf),\n",
        "    ('adaboost', adaboost_clf)\n",
        "]\n",
        "\n",
        "# Define stacking model\n",
        "stacking_classifier = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=final_estimator,\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'catboost__depth': randint(4, 10),\n",
        "    'final_estimator__C': uniform(0.1, 10),\n",
        "    'adaboost__n_estimators': randint(50, 500),\n",
        "    'adaboost__learning_rate': uniform(0.01, 1)\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "rand_search = RandomizedSearchCV(stacking_classifier, param_grid, cv=2, n_iter=5, scoring='roc_auc', n_jobs=-1, random_state=42, verbose=2)\n",
        "\n",
        "# Assuming X_train and y_train are your training dataset\n",
        "rand_search.fit(X_train, y_train)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "best_model = rand_search.best_estimator_\n",
        "y_pred = best_model.predict(X_train)\n",
        "print(\"Best parameters:\", rand_search.best_params_)\n",
        "print(\"ROC_AUC Score: \", rand_search.best_score_)\n",
        "print(accuracy_score(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}