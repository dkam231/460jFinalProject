digraph {
	graph [size="18.45,18.45"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2535702126448 [label="
 (1, 8)" fillcolor=darkolivegreen1]
	2536514092288 [label=AddmmBackward0]
	2536514087824 -> 2536514092288
	2535990925104 [label="layers.17.bias
 (8)" fillcolor=lightblue]
	2535990925104 -> 2536514087824
	2536514087824 [label=AccumulateGrad]
	2536514089936 -> 2536514092288
	2536514089936 [label=LeakyReluBackward0]
	2536514089408 -> 2536514089936
	2536514089408 [label=NativeBatchNormBackward0]
	2536514087344 -> 2536514089408
	2536514087344 [label=AddmmBackward0]
	2536514088256 -> 2536514087344
	2535981595728 [label="layers.14.bias
 (128)" fillcolor=lightblue]
	2535981595728 -> 2536514088256
	2536514088256 [label=AccumulateGrad]
	2536514091280 -> 2536514087344
	2536514091280 [label=LeakyReluBackward0]
	2535757949168 -> 2536514091280
	2535757949168 [label=NativeBatchNormBackward0]
	2535694242080 -> 2535757949168
	2535694242080 [label=AddmmBackward0]
	2535693774912 -> 2535694242080
	2535981584304 [label="layers.11.bias
 (256)" fillcolor=lightblue]
	2535981584304 -> 2535693774912
	2535693774912 [label=AccumulateGrad]
	2535999015136 -> 2535694242080
	2535999015136 [label=LeakyReluBackward0]
	2536311558048 -> 2535999015136
	2536311558048 [label=NativeBatchNormBackward0]
	2535981298736 -> 2536311558048
	2535981298736 [label=AddmmBackward0]
	2535981299024 -> 2535981298736
	2535981594000 [label="layers.7.bias
 (512)" fillcolor=lightblue]
	2535981594000 -> 2535981299024
	2535981299024 [label=AccumulateGrad]
	2535981298880 -> 2535981298736
	2535981298880 [label=LeakyReluBackward0]
	2535981297488 -> 2535981298880
	2535981297488 [label=AddmmBackward0]
	2535981300896 -> 2535981297488
	2535981581904 [label="layers.4.bias
 (1024)" fillcolor=lightblue]
	2535981581904 -> 2535981300896
	2535981300896 [label=AccumulateGrad]
	2535981297632 -> 2535981297488
	2535981297632 [label=LeakyReluBackward0]
	2535981301088 -> 2535981297632
	2535981301088 [label=AddmmBackward0]
	2535981289328 -> 2535981301088
	2535981582288 [label="layers.1.bias
 (2048)" fillcolor=lightblue]
	2535981582288 -> 2535981289328
	2535981289328 [label=AccumulateGrad]
	2535981300992 -> 2535981301088
	2535981300992 [label=NativeBatchNormBackward0]
	2535981296336 -> 2535981300992
	2536465798384 [label="layers.0.weight
 (1186)" fillcolor=lightblue]
	2536465798384 -> 2535981296336
	2535981296336 [label=AccumulateGrad]
	2535981292688 -> 2535981300992
	2537041582448 [label="layers.0.bias
 (1186)" fillcolor=lightblue]
	2537041582448 -> 2535981292688
	2535981292688 [label=AccumulateGrad]
	2535981293984 -> 2535981301088
	2535981293984 [label=TBackward0]
	2535981285824 -> 2535981293984
	2535981593424 [label="layers.1.weight
 (2048, 1186)" fillcolor=lightblue]
	2535981593424 -> 2535981285824
	2535981285824 [label=AccumulateGrad]
	2535981297680 -> 2535981297488
	2535981297680 [label=TBackward0]
	2535981289280 -> 2535981297680
	2535981581424 [label="layers.4.weight
 (1024, 2048)" fillcolor=lightblue]
	2535981581424 -> 2535981289280
	2535981289280 [label=AccumulateGrad]
	2535981298832 -> 2535981298736
	2535981298832 [label=TBackward0]
	2535981286976 -> 2535981298832
	2535981593904 [label="layers.7.weight
 (512, 1024)" fillcolor=lightblue]
	2535981593904 -> 2535981286976
	2535981286976 [label=AccumulateGrad]
	2535981298976 -> 2536311558048
	2535981580464 [label="layers.8.weight
 (512)" fillcolor=lightblue]
	2535981580464 -> 2535981298976
	2535981298976 [label=AccumulateGrad]
	2535981298928 -> 2536311558048
	2535981582960 [label="layers.8.bias
 (512)" fillcolor=lightblue]
	2535981582960 -> 2535981298928
	2535981298928 [label=AccumulateGrad]
	2536465048016 -> 2535694242080
	2536465048016 [label=TBackward0]
	2536518008304 -> 2536465048016
	2535981586992 [label="layers.11.weight
 (256, 512)" fillcolor=lightblue]
	2535981586992 -> 2536518008304
	2536518008304 [label=AccumulateGrad]
	2535694244192 -> 2535757949168
	2535981587952 [label="layers.12.weight
 (256)" fillcolor=lightblue]
	2535981587952 -> 2535694244192
	2535694244192 [label=AccumulateGrad]
	2536465055024 -> 2535757949168
	2535981585264 [label="layers.12.bias
 (256)" fillcolor=lightblue]
	2535981585264 -> 2536465055024
	2536465055024 [label=AccumulateGrad]
	2535757948352 -> 2536514087344
	2535757948352 [label=TBackward0]
	2536311566832 -> 2535757948352
	2535981592176 [label="layers.14.weight
 (128, 256)" fillcolor=lightblue]
	2535981592176 -> 2536311566832
	2536311566832 [label=AccumulateGrad]
	2536514091424 -> 2536514089408
	2535981593808 [label="layers.15.weight
 (128)" fillcolor=lightblue]
	2535981593808 -> 2536514091424
	2536514091424 [label=AccumulateGrad]
	2536514090176 -> 2536514089408
	2535990930096 [label="layers.15.bias
 (128)" fillcolor=lightblue]
	2535990930096 -> 2536514090176
	2536514090176 [label=AccumulateGrad]
	2536514092000 -> 2536514092288
	2536514092000 [label=TBackward0]
	2536465051280 -> 2536514092000
	2535990919248 [label="layers.17.weight
 (8, 128)" fillcolor=lightblue]
	2535990919248 -> 2536465051280
	2536465051280 [label=AccumulateGrad]
	2536514092288 -> 2535702126448
}
