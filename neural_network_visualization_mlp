digraph {
	graph [size="18.45,18.45"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1607584106544 [label="
 (1, 8)" fillcolor=darkolivegreen1]
	1606161134592 [label=AddmmBackward0]
	1607583393072 -> 1606161134592
	1607584118352 [label="layers.17.bias
 (8)" fillcolor=lightblue]
	1607584118352 -> 1607583393072
	1607583393072 [label=AccumulateGrad]
	1607583393024 -> 1606161134592
	1607583393024 [label=ReluBackward0]
	1607583391632 -> 1607583393024
	1607583391632 [label=NativeBatchNormBackward0]
	1607583395040 -> 1607583391632
	1607583395040 [label=AddmmBackward0]
	1607583389232 -> 1607583395040
	1607584119024 [label="layers.14.bias
 (128)" fillcolor=lightblue]
	1607584119024 -> 1607583389232
	1607583389232 [label=AccumulateGrad]
	1607583398304 -> 1607583395040
	1607583398304 [label=ReluBackward0]
	1607583387312 -> 1607583398304
	1607583387312 [label=NativeBatchNormBackward0]
	1607583388992 -> 1607583387312
	1607583388992 [label=AddmmBackward0]
	1607583396288 -> 1607583388992
	1607583709232 [label="layers.11.bias
 (256)" fillcolor=lightblue]
	1607583709232 -> 1607583396288
	1607583396288 [label=AccumulateGrad]
	1607583398928 -> 1607583388992
	1607583398928 [label=ReluBackward0]
	1607583393600 -> 1607583398928
	1607583393600 [label=NativeBatchNormBackward0]
	1607583388704 -> 1607583393600
	1607583388704 [label=AddmmBackward0]
	1607583398832 -> 1607583388704
	1607582880720 [label="layers.7.bias
 (512)" fillcolor=lightblue]
	1607582880720 -> 1607583398832
	1607583398832 [label=AccumulateGrad]
	1607583395856 -> 1607583388704
	1607583395856 [label=ReluBackward0]
	1607583392880 -> 1607583395856
	1607583392880 [label=AddmmBackward0]
	1607583389856 -> 1607583392880
	1606159603600 [label="layers.4.bias
 (1024)" fillcolor=lightblue]
	1606159603600 -> 1607583389856
	1607583389856 [label=AccumulateGrad]
	1607583390720 -> 1607583392880
	1607583390720 [label=ReluBackward0]
	1607583384480 -> 1607583390720
	1607583384480 [label=AddmmBackward0]
	1607583389616 -> 1607583384480
	1606159613296 [label="layers.1.bias
 (2048)" fillcolor=lightblue]
	1606159613296 -> 1607583389616
	1607583389616 [label=AccumulateGrad]
	1607583384048 -> 1607583384480
	1607583384048 [label=NativeBatchNormBackward0]
	1607583390336 -> 1607583384048
	1606159602352 [label="layers.0.weight
 (1185)" fillcolor=lightblue]
	1606159602352 -> 1607583390336
	1607583390336 [label=AccumulateGrad]
	1607583397008 -> 1607583384048
	1606159600912 [label="layers.0.bias
 (1185)" fillcolor=lightblue]
	1606159600912 -> 1607583397008
	1607583397008 [label=AccumulateGrad]
	1607583392400 -> 1607583384480
	1607583392400 [label=TBackward0]
	1607583392208 -> 1607583392400
	1606159602160 [label="layers.1.weight
 (2048, 1185)" fillcolor=lightblue]
	1606159602160 -> 1607583392208
	1607583392208 [label=AccumulateGrad]
	1607583394368 -> 1607583392880
	1607583394368 [label=TBackward0]
	1607583397200 -> 1607583394368
	1606159603504 [label="layers.4.weight
 (1024, 2048)" fillcolor=lightblue]
	1606159603504 -> 1607583397200
	1607583397200 [label=AccumulateGrad]
	1607583392832 -> 1607583388704
	1607583392832 [label=TBackward0]
	1607583393648 -> 1607583392832
	1606159606288 [label="layers.7.weight
 (512, 1024)" fillcolor=lightblue]
	1606159606288 -> 1607583393648
	1607583393648 [label=AccumulateGrad]
	1607583393456 -> 1607583393600
	1607583709136 [label="layers.8.weight
 (512)" fillcolor=lightblue]
	1607583709136 -> 1607583393456
	1607583393456 [label=AccumulateGrad]
	1607583397824 -> 1607583393600
	1607583709328 [label="layers.8.bias
 (512)" fillcolor=lightblue]
	1607583709328 -> 1607583397824
	1607583397824 [label=AccumulateGrad]
	1607583389088 -> 1607583388992
	1607583389088 [label=TBackward0]
	1607583396576 -> 1607583389088
	1607583708080 [label="layers.11.weight
 (256, 512)" fillcolor=lightblue]
	1607583708080 -> 1607583396576
	1607583396576 [label=AccumulateGrad]
	1607583394752 -> 1607583387312
	1607584119600 [label="layers.12.weight
 (256)" fillcolor=lightblue]
	1607584119600 -> 1607583394752
	1607583394752 [label=AccumulateGrad]
	1607583387504 -> 1607583387312
	1607584119504 [label="layers.12.bias
 (256)" fillcolor=lightblue]
	1607584119504 -> 1607583387504
	1607583387504 [label=AccumulateGrad]
	1607583391680 -> 1607583395040
	1607583391680 [label=TBackward0]
	1607583385824 -> 1607583391680
	1607584119120 [label="layers.14.weight
 (128, 256)" fillcolor=lightblue]
	1607584119120 -> 1607583385824
	1607583385824 [label=AccumulateGrad]
	1607583391392 -> 1607583391632
	1607584118928 [label="layers.15.weight
 (128)" fillcolor=lightblue]
	1607584118928 -> 1607583391392
	1607583391392 [label=AccumulateGrad]
	1607583399552 -> 1607583391632
	1607584118832 [label="layers.15.bias
 (128)" fillcolor=lightblue]
	1607584118832 -> 1607583399552
	1607583399552 [label=AccumulateGrad]
	1607583390768 -> 1606161134592
	1607583390768 [label=TBackward0]
	1607583394128 -> 1607583390768
	1607584118448 [label="layers.17.weight
 (8, 128)" fillcolor=lightblue]
	1607584118448 -> 1607583394128
	1607583394128 [label=AccumulateGrad]
	1606161134592 -> 1607584106544
}
